{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b4a7feef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import argparse\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader\n",
    "import transformers\n",
    "import os\n",
    "import tqdm\n",
    "from transformers import AutoTokenizer\n",
    "import pandas as pd\n",
    "from model import BertLinear\n",
    "from useful_functions import seed_everything, load_embedding, CollateFunctor, get_mapping_matrix_batched, train_epochs, get_avg_words_from_bert\n",
    "from dataset import EmbDataset, open_and_read_path, TokenDataset, drop_rows\n",
    "import torch\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import gensim\n",
    "import zipfile\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertModel\n",
    "from typing import List, Tuple\n",
    "import tqdm\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import tqdm\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Optimizer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "8b8f80ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_and_read_val_path(data_path):\n",
    "    with open(data_path, \"rb\") as f:\n",
    "        data = io.TextIOWrapper(f, encoding=\"utf-8\").read()\n",
    "\n",
    "    # Parse the CoNLL-U file using conllu library\n",
    "    parsed_data = conllu.parse(data)\n",
    "\n",
    "    # Extract the token and named entity label from the CoNLL-U file\n",
    "    sentences = []\n",
    "    tags = []\n",
    "    labels = []\n",
    "    metadata = []\n",
    "    sentence_length = []\n",
    "    for sentence in parsed_data:\n",
    "        tokens = []\n",
    "        tokens_tags = []\n",
    "        token_label = []\n",
    "        token_metadata = []\n",
    "        for token in sentence:\n",
    "            # Extract the token and named entity label\n",
    "            tokens.append(token['form'])\n",
    "            tokens_tags.append(token[\"upos\"])\n",
    "            token_label.append(token['misc']['name'])\n",
    "            token_metadata.append(token['feats'])\n",
    "        sentences.append(\" \".join(tokens))\n",
    "        tags.append(\" \".join(tokens_tags))\n",
    "        labels.append(\" \".join(token_label))\n",
    "        metadata.append(token_metadata)\n",
    "        sentence_length.append(len(token_label))\n",
    "\n",
    "    data_dict = {\"sentence\" : sentences,\n",
    "                 \"labels\" : labels,\n",
    "                 \"sentence_length\" : sentence_length}\n",
    "\n",
    "    data = pd.DataFrame(data_dict)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d78066c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "#os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7be6a94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5550"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class dotdict(dict):\n",
    "    \"\"\"dot.notation access to dictionary attributes\"\"\"\n",
    "    __getattr__ = dict.get\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__\n",
    "\n",
    "args = {\"data_path\" : \"data/norne-nb-in5550-train.conllu.gz\",\n",
    "        \"hidden_size\" : 256,\n",
    "        \"num_layers\" : 2,\n",
    "        \"batch_size\" : 32,\n",
    "        \"lr\" : 0.0005,\n",
    "        \"epochs\" : 1,\n",
    "        \"split\" : 0.8,\n",
    "        \"max_length\" : 64,\n",
    "        \"dropout\" : 0.1,\n",
    "        \"seed\" : 5550,\n",
    "        \"freeze\" : True}\n",
    "\n",
    "args = dotdict(args)\n",
    "args.seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "706873d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "data_path = args.data_path\n",
    "with gzip.open(data_path, \"rb\") as f:\n",
    "    data = io.TextIOWrapper(f, encoding=\"utf-8\").read()\n",
    "    print(\"1\")\n",
    "    parsed_data = conllu.parse(data)\n",
    "    print(\"2\")\n",
    "    train_conllu, val_conllu = train_test_split(parsed_data, train_size=args.split, random_state=args.seed)\n",
    "    print(\"3\")\n",
    "    output_path = \"data/gold_label_val.conllu.gz\"\n",
    "    print(\"4\")\n",
    "    sentence = val_conllu[0]\n",
    "    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        for sent in val_conllu:\n",
    "            f.write(sent.serialize())\n",
    "        #f.write(conllu.serialize(val_conllu))\n",
    "        #f.write(val_conllu.serialize())\n",
    "        #f.write(sentence.serialize())\n",
    "    \n",
    "    print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "b4a26423",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TokenList<-, Det, er, klart, ., metadata={text: \"- Det er klart.\"}>, TokenList<Nordmenn, har, lidd, av, et, lillebrorkompleks, som, i, de, siste, årtier, har, gått, over, til, en, raskt, voksende, selvfølelse, ., metadata={text: \"Nordmenn har lidd av et lillebrorkompleks som i de siste årtier har gått over til en raskt voksende selvfølelse.\"}>, TokenList<Bebyggelsen, i, bruk, ligger, på, sørsiden, av, øya, ,, og, her, er, også, avfallsfyllingen, ., metadata={text: \"Bebyggelsen i bruk ligger på sørsiden av øya, og her er også avfallsfyllingen.\"}>, TokenList<Han, mener, det, er, for, tidlig, å, trekke, konklusjoner, om, partiets, veivalg, fram, mot, stortingsvalget, i, 2013, ., metadata={text: \"Han mener det er for tidlig å trekke konklusjoner om partiets veivalg fram mot stortingsvalget i 2013.\"}>, TokenList<Se, og, hør, Erik, Hamréns, kunstgress-angrep, metadata={text: \"Se og hør Erik Hamréns kunstgress-angrep\"}>]"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = \"data/gold_label_val.conllu.gz\"\n",
    "#parsed_data = conllu.parse(open(data_path, \"r\", encoding='utf8').read())\n",
    "with open(data_path, \"rb\") as f:\n",
    "    data = io.TextIOWrapper(f, encoding=\"utf-8\").read()\n",
    "\n",
    "parsed_data = conllu.parse(data)\n",
    "len(parsed_data)\n",
    "parsed_data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "8b0ac59c",
   "metadata": {},
   "outputs": [
    {
     "ename": "BadGzipFile",
     "evalue": "Not a gzipped file (b'# ')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBadGzipFile\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [253], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m val_data \u001b[38;5;241m=\u001b[39m \u001b[43mopen_and_read_val_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m val_data\n",
      "Cell \u001b[0;32mIn [252], line 3\u001b[0m, in \u001b[0;36mopen_and_read_val_path\u001b[0;34m(data_path)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mopen_and_read_val_path\u001b[39m(data_path):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m gzip\u001b[38;5;241m.\u001b[39mopen(data_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m----> 3\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTextIOWrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m# Parse the CoNLL-U file using conllu library\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     parsed_data \u001b[38;5;241m=\u001b[39m conllu\u001b[38;5;241m.\u001b[39mparse(data)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/gzip.py:301\u001b[0m, in \u001b[0;36mGzipFile.read\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    299\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01merrno\u001b[39;00m\n\u001b[1;32m    300\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(errno\u001b[38;5;241m.\u001b[39mEBADF, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread() on write-only GzipFile object\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 301\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_buffer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/_compression.py:118\u001b[0m, in \u001b[0;36mDecompressReader.readall\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    114\u001b[0m chunks \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    115\u001b[0m \u001b[38;5;66;03m# sys.maxsize means the max length of output buffer is unlimited,\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;66;03m# so that the whole input buffer can be decompressed within one\u001b[39;00m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;66;03m# .decompress() call.\u001b[39;00m\n\u001b[0;32m--> 118\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m data \u001b[38;5;241m:=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaxsize\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    119\u001b[0m     chunks\u001b[38;5;241m.\u001b[39mappend(data)\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(chunks)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/gzip.py:492\u001b[0m, in \u001b[0;36m_GzipReader.read\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    488\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_new_member:\n\u001b[1;32m    489\u001b[0m     \u001b[38;5;66;03m# If the _new_member flag is set, we have to\u001b[39;00m\n\u001b[1;32m    490\u001b[0m     \u001b[38;5;66;03m# jump to the next member, if there is one.\u001b[39;00m\n\u001b[1;32m    491\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_read()\n\u001b[0;32m--> 492\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_gzip_header\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    493\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pos\n\u001b[1;32m    494\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/gzip.py:440\u001b[0m, in \u001b[0;36m_GzipReader._read_gzip_header\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    437\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m magic \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\037\u001b[39;00m\u001b[38;5;130;01m\\213\u001b[39;00m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 440\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m BadGzipFile(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNot a gzipped file (\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m magic)\n\u001b[1;32m    442\u001b[0m (method, flag,\n\u001b[1;32m    443\u001b[0m  \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_last_mtime) \u001b[38;5;241m=\u001b[39m struct\u001b[38;5;241m.\u001b[39munpack(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<BBIxx\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_exact(\u001b[38;5;241m8\u001b[39m))\n\u001b[1;32m    444\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m8\u001b[39m:\n",
      "\u001b[0;31mBadGzipFile\u001b[0m: Not a gzipped file (b'# ')"
     ]
    }
   ],
   "source": [
    "val_data = open_and_read_val_path(data_path)\n",
    "val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "54aaa83e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data ...\n",
      "Loading data done\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>labels</th>\n",
       "      <th>sentence_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rus har en klar sosial dimensjon ; man drikker...</td>\n",
       "      <td>O O O O O O O O O O O O O O O O O O O O O O O O</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I tillegg skal daglig leder ved Miljøtransport...</td>\n",
       "      <td>O O O O O O B-ORG I-ORG O O O O O O O O O O O ...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>« Angående vår nærmere lovede undersøkelse på ...</td>\n",
       "      <td>O O O O O O O O O O O O O O O O O O O O O O O ...</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>- I verste fall kan det være dødelig hvis du s...</td>\n",
       "      <td>O O O O O O O O O O O O O O O B-PER O</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>At vi i det hele tatt har det er et resultat a...</td>\n",
       "      <td>O O O O O O O O O O O O O O O O O O O B-LOC O ...</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18093</th>\n",
       "      <td>- Bryne er et søppellag</td>\n",
       "      <td>O B-ORG O O O</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18094</th>\n",
       "      <td>I så fall har Ulsrud sikret EM-medalje nok en ...</td>\n",
       "      <td>O O O O B-PER O O O O O O</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18095</th>\n",
       "      <td>Men det vil alltid , som jeg har sagt tidliger...</td>\n",
       "      <td>O O O O O O O O O O O O O O O O O O O O O O</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18096</th>\n",
       "      <td>Vi vil finne løsninger som reduserer utslippen...</td>\n",
       "      <td>O O O O O O O O O O</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18097</th>\n",
       "      <td>- Jeg kjørte ikke spesielt bra , jeg var alt f...</td>\n",
       "      <td>O O O O O O O O O O O O O O O</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18098 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                sentence  \\\n",
       "0      Rus har en klar sosial dimensjon ; man drikker...   \n",
       "1      I tillegg skal daglig leder ved Miljøtransport...   \n",
       "2      « Angående vår nærmere lovede undersøkelse på ...   \n",
       "3      - I verste fall kan det være dødelig hvis du s...   \n",
       "4      At vi i det hele tatt har det er et resultat a...   \n",
       "...                                                  ...   \n",
       "18093                            - Bryne er et søppellag   \n",
       "18094  I så fall har Ulsrud sikret EM-medalje nok en ...   \n",
       "18095  Men det vil alltid , som jeg har sagt tidliger...   \n",
       "18096  Vi vil finne løsninger som reduserer utslippen...   \n",
       "18097  - Jeg kjørte ikke spesielt bra , jeg var alt f...   \n",
       "\n",
       "                                                  labels  sentence_length  \n",
       "0        O O O O O O O O O O O O O O O O O O O O O O O O               24  \n",
       "1      O O O O O O B-ORG I-ORG O O O O O O O O O O O ...               27  \n",
       "2      O O O O O O O O O O O O O O O O O O O O O O O ...               26  \n",
       "3                  O O O O O O O O O O O O O O O B-PER O               17  \n",
       "4      O O O O O O O O O O O O O O O O O O O B-LOC O ...               26  \n",
       "...                                                  ...              ...  \n",
       "18093                                      O B-ORG O O O                5  \n",
       "18094                          O O O O B-PER O O O O O O               11  \n",
       "18095        O O O O O O O O O O O O O O O O O O O O O O               22  \n",
       "18096                                O O O O O O O O O O               10  \n",
       "18097                      O O O O O O O O O O O O O O O               15  \n",
       "\n",
       "[18098 rows x 3 columns]"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed_everything(args.seed)\n",
    "\n",
    "print(\"Loading data ...\")\n",
    "data = open_and_read_path(args.data_path)\n",
    "print(\"Loading data done\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "d12eb82c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model ...\n",
      "Loading model done\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading model ...\")\n",
    "# test tokenizer:\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "\n",
    "# norbert_path = \"/fp/projects01/ec30/models/norlm/NorBERT2/\"\n",
    "# tokenizer = transformers.BertTokenizer.from_pretrained(norbert_path)\n",
    "# model = transformers.BertModel.from_pretrained(norbert_path)\n",
    "print(\"Loading model done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "54697af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting and processing data ...\n"
     ]
    }
   ],
   "source": [
    "print(\"Splitting and processing data ...\")\n",
    "train_df, val_df = train_test_split(data, train_size=args.split, random_state=args.seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "8a38382e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>labels</th>\n",
       "      <th>sentence_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3058</th>\n",
       "      <td>- Det er klart .</td>\n",
       "      <td>O O O O O</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7156</th>\n",
       "      <td>Nordmenn har lidd av et lillebrorkompleks som ...</td>\n",
       "      <td>O O O O O O O O O O O O O O O O O O O O</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023</th>\n",
       "      <td>Bebyggelsen i bruk ligger på sørsiden av øya ,...</td>\n",
       "      <td>O O O O O O O O O O O O O O O</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2634</th>\n",
       "      <td>Han mener det er for tidlig å trekke konklusjo...</td>\n",
       "      <td>O O O O O O O O O O O O O O O O O O</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5607</th>\n",
       "      <td>Se og hør Erik Hamréns kunstgress-angrep</td>\n",
       "      <td>O O O B-PER I-PER O</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16387</th>\n",
       "      <td>- Det betyr i beste fall at filmen har rørt ve...</td>\n",
       "      <td>O O O O O O O O O O O O O</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7572</th>\n",
       "      <td>Konserter holdes hele året , men verdt å merke...</td>\n",
       "      <td>O O O O O O O O O O O B-EVT O O O O O O O O O ...</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16027</th>\n",
       "      <td>Likevel engasjerte han seg i samværssaker .</td>\n",
       "      <td>O O O O O O O</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12680</th>\n",
       "      <td>Mens de rødgrønne frir uhemmet til KrF , beveg...</td>\n",
       "      <td>O O O O O O B-ORG O O B-ORG O O O B-ORG O B-ORG</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6858</th>\n",
       "      <td>Gjennom risikogjennomganger og evalueringer ka...</td>\n",
       "      <td>O O O O O O O O O O O O O O O O O O O O O O</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3620 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                sentence  \\\n",
       "3058                                    - Det er klart .   \n",
       "7156   Nordmenn har lidd av et lillebrorkompleks som ...   \n",
       "2023   Bebyggelsen i bruk ligger på sørsiden av øya ,...   \n",
       "2634   Han mener det er for tidlig å trekke konklusjo...   \n",
       "5607            Se og hør Erik Hamréns kunstgress-angrep   \n",
       "...                                                  ...   \n",
       "16387  - Det betyr i beste fall at filmen har rørt ve...   \n",
       "7572   Konserter holdes hele året , men verdt å merke...   \n",
       "16027        Likevel engasjerte han seg i samværssaker .   \n",
       "12680  Mens de rødgrønne frir uhemmet til KrF , beveg...   \n",
       "6858   Gjennom risikogjennomganger og evalueringer ka...   \n",
       "\n",
       "                                                  labels  sentence_length  \n",
       "3058                                           O O O O O                5  \n",
       "7156             O O O O O O O O O O O O O O O O O O O O               20  \n",
       "2023                       O O O O O O O O O O O O O O O               15  \n",
       "2634                 O O O O O O O O O O O O O O O O O O               18  \n",
       "5607                                 O O O B-PER I-PER O                6  \n",
       "...                                                  ...              ...  \n",
       "16387                          O O O O O O O O O O O O O               13  \n",
       "7572   O O O O O O O O O O O B-EVT O O O O O O O O O ...               26  \n",
       "16027                                      O O O O O O O                7  \n",
       "12680    O O O O O O B-ORG O O B-ORG O O O B-ORG O B-ORG               16  \n",
       "6858         O O O O O O O O O O O O O O O O O O O O O O               22  \n",
       "\n",
       "[3620 rows x 3 columns]"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c6130da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting and processing data ...\n",
      "\tLoading tokenized data for Task 2 ...\n",
      "\tLoading tokenized data for Task 2 done\n",
      "Splitting and processing data done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(\"\\tLoading tokenized data for Task 2 ...\")\n",
    "tok_train_dataset = TokenDataset(train_df, tokenizer, args)\n",
    "tok_val_dataset = TokenDataset(\n",
    "    val_df, tokenizer, args, label_vocab=tok_train_dataset.label_vocab)\n",
    "\n",
    "tok_train_dataloader = DataLoader(tok_train_dataset,\n",
    "                                batch_size=args.batch_size,\n",
    "                                shuffle=True,\n",
    "                                drop_last=True,\n",
    "                                num_workers=1\n",
    "                                )\n",
    "\n",
    "tok_val_dataloader = DataLoader(tok_val_dataset,\n",
    "                                batch_size=args.batch_size,\n",
    "                                shuffle=False,\n",
    "                                drop_last=False,\n",
    "                                num_workers=1\n",
    "                                )\n",
    "print(\"\\tLoading tokenized data for Task 2 done\")\n",
    "\n",
    "print(\"Splitting and processing data done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "875daefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model: nn.Module, train_iter: DataLoader, optimizer: Optimizer, scheduler: _LRScheduler):\n",
    "    \"\"\" Training process of Neural-Network.\n",
    "        Parameters\n",
    "        ----------\n",
    "        model: nn.Module - the neural network to train\n",
    "        train_iter: torch.utils.data.DataLoader\n",
    "        optimizer: torch.optim.Optimizer - Optimzer method\n",
    "        scheduler: torch.optim.lr_scheduler._LRScheduler - Scheduler method\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        blank\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    for input_ids, attention_mask, y, offset_mapping, word_length  in tqdm.tqdm(train_iter):\n",
    "        input_ids, attention_mask, y, offset_mapping, word_length  = input_ids.to(device), attention_mask.to(device), y.to(device), offset_mapping.to(device), word_length.to(device) \n",
    "        optimizer.zero_grad()\n",
    "        n_subwords = input_ids.size(1)\n",
    "        n_words = max(len(words) for words in word_length)\n",
    "        mapping_matrix = get_mapping_matrix_batched(offset_mapping, word_length, n_subwords, n_words)\n",
    "        predictions = model(input_ids, attention_mask, mapping_matrix)\n",
    "        predictions = predictions.permute(0, 2, 1)\n",
    "        loss = F.cross_entropy(predictions, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model: nn.Module, data_iter: DataLoader):\n",
    "    \"\"\" Retrives the accuracy of the neural network \n",
    "        Parameters\n",
    "        ----------\n",
    "        model: nn.Module - the neural network used to predict\n",
    "        data_iter: torch.utils.data.DataLoader\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        accuracy: float value\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    labels_true, predictions = [], []\n",
    "    for input_ids, attention_mask, y, offset_mapping, word_length  in tqdm.tqdm(data_iter):\n",
    "        input_ids, attention_mask, y, offset_mapping, word_length  = input_ids.to(device), attention_mask.to(device), y.to(device), offset_mapping.to(device), word_length.to(device) \n",
    "        n_subwords = input_ids.size(1)\n",
    "        n_words = max(len(words) for words in word_length)\n",
    "        mapping_matrix = get_mapping_matrix_batched(offset_mapping, word_length, n_subwords, n_words)\n",
    "        pred = model(input_ids, attention_mask, mapping_matrix)\n",
    "        #print(\"input:\", input_ids)\n",
    "        #print(\"label:\", y)\n",
    "        #print(\"pred:\", pred.argmax(dim=2).tolist())\n",
    "        predictions += pred.argmax(dim=2).tolist()\n",
    "        labels_true += y.tolist()\n",
    "        \n",
    "    \n",
    "    \n",
    "    return (torch.tensor(predictions) == torch.tensor(labels_true)).float().mean() * 100.0\n",
    "\n",
    "def train_epochs(args, model, optimizer, scheduler, train_iter, val_iter):\n",
    "    \"\"\" Calculating training and validation accuracy per epoch.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        epochs: int\n",
    "        args: argparse.ArgumentParser\n",
    "        optimizer: torch.optim.Optimizer - Optimzer method\n",
    "        scheduler: torch.optim.lr_scheduler._LRScheduler - Scheduler method\n",
    "        train_iter: torch.utils.data.DataLoader\n",
    "        val_iter: torch.utils.data.DataLoader\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        train_accuracy: float\n",
    "        val_accuracy: float\n",
    "    \"\"\"\n",
    "    for epoch in range(args.epochs):\n",
    "        train(model, train_iter, optimizer, scheduler)\n",
    "\n",
    "        train_accuracy = evaluate(model, train_iter)\n",
    "        val_accuracy = evaluate(model, val_iter)\n",
    "\n",
    "        print(f\"epoch: {epoch}\\tTraining accuracy: {train_accuracy:.1f}%\")\n",
    "        print(f\"Validation accuracy: {val_accuracy:.1f}%\\n\")\n",
    "    return train_accuracy, val_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1a6f019c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "print(\"Training model ...\")\n",
    "bert = BertLinear(\"bert-base-cased\", num_labels=17)\n",
    "optimizer = torch.optim.AdamW(bert.parameters(), lr=args.lr, weight_decay=0.0)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, args.epochs * len(tok_train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2012ebb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                    | 0/15 [00:00<?, ?it/s]2023-04-10 16:42:50.587524: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "100%|███████████████████████████████████████████| 15/15 [02:07<00:00,  8.50s/it]\n",
      "2023-04-10 16:44:58.191509: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-10 16:45:06.147247: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-10 16:45:12.047694: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-10 16:45:17.822232: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Caught TypeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py\", line 302, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 58, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 58, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\nTypeError: 'DataLoader' object is not subscriptable\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [24], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain_epochs\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbert\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtok_train_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtok_val_dataloader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining model done\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/Uio/IN5550/oblig/IN5550/oblig3/useful_functions.py:226\u001b[0m, in \u001b[0;36mtrain_epochs\u001b[0;34m(args, model, optimizer, scheduler, train_iter, val_iter)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(args\u001b[38;5;241m.\u001b[39mepochs):\n\u001b[1;32m    224\u001b[0m     train(model, train_iter, optimizer, scheduler)\n\u001b[0;32m--> 226\u001b[0m     train_accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    227\u001b[0m     val_accuracy \u001b[38;5;241m=\u001b[39m evaluate(model, val_iter)\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mTraining accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_accuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/Uio/IN5550/oblig/IN5550/oblig3/useful_functions.py:374\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(model, test_dataset)\u001b[0m\n\u001b[1;32m    371\u001b[0m debug \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    373\u001b[0m true_labels, prediction \u001b[38;5;241m=\u001b[39m [], []\n\u001b[0;32m--> 374\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m test_data, test_label \u001b[38;5;129;01min\u001b[39;00m test_dataloader:\n\u001b[1;32m    376\u001b[0m         test_label \u001b[38;5;241m=\u001b[39m test_label\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    377\u001b[0m         mask \u001b[38;5;241m=\u001b[39m test_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    626\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    627\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 628\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    629\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    631\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    632\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1333\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1331\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1332\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_task_info[idx]\n\u001b[0;32m-> 1333\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1359\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1357\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_put_index()\n\u001b[1;32m   1358\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[0;32m-> 1359\u001b[0m     \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1360\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/_utils.py:543\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    540\u001b[0m     \u001b[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[1;32m    541\u001b[0m     \u001b[38;5;66;03m# instantiate since we don't know how to\u001b[39;00m\n\u001b[1;32m    542\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m--> 543\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "\u001b[0;31mTypeError\u001b[0m: Caught TypeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py\", line 302, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 58, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 58, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\nTypeError: 'DataLoader' object is not subscriptable\n"
     ]
    }
   ],
   "source": [
    "train_epochs(args, bert, optimizer, scheduler, tok_train_dataloader, tok_val_dataloader)\n",
    "\n",
    "print(\"Training model done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5b72c29c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = [16, 16, 16, 16]\n",
    "prediction.count(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6716c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
