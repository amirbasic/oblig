{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "2aa4e8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import conllu\n",
    "import gzip\n",
    "import io\n",
    "import transformers\n",
    "from transformers import AutoTokenizer\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "import random\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "import gensim\n",
    "from transformers import BertForSequenceClassification, AutoTokenizer\n",
    "from transformers import BertTokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import ClassLabel\n",
    "from torch.utils.data import DataLoader\n",
    "from typing import List, Tuple\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "369734a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed_value=5550):\n",
    "    \"Set same seed to all random operations for reproduceability purposes\"\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed_value)\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    torch.cuda.manual_seed_all(seed_value)\n",
    "\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "seed_everything()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "38dc065d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embedding ...\n",
      "Loading embedding done\n"
     ]
    }
   ],
   "source": [
    "def load_embedding(modelfile):\n",
    "    \" Loading the file that is used as the embedding layer in the Neural Network\"\n",
    "    # Detect the model format by its extension:\n",
    "    # Binary word2vec format:\n",
    "    if modelfile.endswith(\".bin.gz\") or modelfile.endswith(\".bin\"):\n",
    "        emb_model = gensim.models.KeyedVectors.load_word2vec_format(\n",
    "            modelfile, binary=True, unicode_errors=\"replace\"\n",
    "        )\n",
    "    # Text word2vec format:\n",
    "    elif (\n",
    "        modelfile.endswith(\".txt.gz\")\n",
    "        or modelfile.endswith(\".txt\")\n",
    "        or modelfile.endswith(\".vec.gz\")\n",
    "        or modelfile.endswith(\".vec\")\n",
    "    ):\n",
    "        emb_model = gensim.models.KeyedVectors.load_word2vec_format(\n",
    "            modelfile, binary=False, unicode_errors=\"replace\"\n",
    "        )\n",
    "    # ZIP archive from the NLPL vector repository:\n",
    "    elif modelfile.endswith(\".zip\"):\n",
    "        with zipfile.ZipFile(modelfile, \"r\") as archive:\n",
    "            stream = archive.open(\n",
    "                \"model.bin\"  # or model.txt, if you want to look at the model\n",
    "            )\n",
    "            emb_model = gensim.models.KeyedVectors.load_word2vec_format(\n",
    "                stream, binary=True, unicode_errors=\"replace\"\n",
    "            )\n",
    "    else:  # Native Gensim format?\n",
    "        emb_model = gensim.models.KeyedVectors.load(modelfile)\n",
    "        #  If you intend to train the model further:\n",
    "        # emb_model = gensim.models.Word2Vec.load(embeddings_file)\n",
    "    return emb_model\n",
    "\n",
    "print(\"Loading embedding ...\")\n",
    "embedding_path = \"data/58/model.bin\"\n",
    "embedding = load_embedding(embedding_path)\n",
    "embedding[\"[UNK]\"] = torch.tensor(embedding.vectors).mean(dim=0).numpy()\n",
    "embedding[\"[PAD]\"] = torch.zeros(embedding.vector_size).numpy()\n",
    "print(\"Loading embedding done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "9d7256ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CollateFunctor:\n",
    "    def __init__(self, padding_index: int, max_length: int):\n",
    "        self.padding_index = padding_index\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __call__(self, samples: List[Tuple[torch.Tensor, torch.Tensor]]) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        input_ids_sentencee = [s for s, y in samples]\n",
    "        labels = [y for s, y in samples]\n",
    "\n",
    "        input_ids_padded_sentence = torch.nn.utils.rnn.pad_sequence(\n",
    "                                    input_ids_sentencee,\n",
    "                                    batch_first = True,\n",
    "                                    padding_value = self.padding_index\n",
    "                                )\n",
    "        \n",
    "        input_ids_padded_sentence = input_ids_padded_sentence[:, :self.max_length]\n",
    "        \n",
    "        labels = torch.LongTensor(labels)\n",
    "        \n",
    "        return input_ids_padded_sentence, labels  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e1ac6b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_and_read_path(data_path):\n",
    "    # Load the CoNLL-U file    \n",
    "    with gzip.open(data_path, \"rb\") as f:\n",
    "        data = io.TextIOWrapper(f, encoding=\"utf-8\").read()\n",
    "\n",
    "    # Parse the CoNLL-U file using conllu library\n",
    "    parsed_data = conllu.parse(data)\n",
    "\n",
    "    # Extract the token and named entity label from the CoNLL-U file\n",
    "    sentences = []\n",
    "    tags = []\n",
    "    labels = []\n",
    "    metadata = []\n",
    "    for sentence in parsed_data:\n",
    "        tokens = []\n",
    "        tokens_tags = []\n",
    "        token_label = []\n",
    "        token_metadata = []\n",
    "        for token in sentence:\n",
    "            # Extract the token and named entity label\n",
    "            tokens.append(token['form'])\n",
    "            tokens_tags.append(token[\"upos\"])\n",
    "            token_label.append(token['misc']['name'])\n",
    "            token_metadata.append(token['feats'])\n",
    "        sentences.append(\" \".join(tokens))\n",
    "        tags.append(\" \".join(tokens_tags))\n",
    "        labels.append(\" \".join(token_label))\n",
    "        metadata.append(token_metadata)\n",
    "\n",
    "    data_dict = {\"sentence\" : sentences,\n",
    "                 \"labels\" : labels}\n",
    "\n",
    "    data = pd.DataFrame(data_dict)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "71547852",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rus har en klar sosial dimensjon ; man drikker...</td>\n",
       "      <td>O O O O O O O O O O O O O O O O O O O O O O O O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I tillegg skal daglig leder ved Miljøtransport...</td>\n",
       "      <td>O O O O O O B-ORG I-ORG O O O O O O O O O O O ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>« Angående vår nærmere lovede undersøkelse på ...</td>\n",
       "      <td>O O O O O O O O O O O O O O O O O O O O O O O ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>- I verste fall kan det være dødelig hvis du s...</td>\n",
       "      <td>O O O O O O O O O O O O O O O B-PER O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>At vi i det hele tatt har det er et resultat a...</td>\n",
       "      <td>O O O O O O O O O O O O O O O O O O O B-LOC O ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  \\\n",
       "0  Rus har en klar sosial dimensjon ; man drikker...   \n",
       "1  I tillegg skal daglig leder ved Miljøtransport...   \n",
       "2  « Angående vår nærmere lovede undersøkelse på ...   \n",
       "3  - I verste fall kan det være dødelig hvis du s...   \n",
       "4  At vi i det hele tatt har det er et resultat a...   \n",
       "\n",
       "                                              labels  \n",
       "0    O O O O O O O O O O O O O O O O O O O O O O O O  \n",
       "1  O O O O O O B-ORG I-ORG O O O O O O O O O O O ...  \n",
       "2  O O O O O O O O O O O O O O O O O O O O O O O ...  \n",
       "3              O O O O O O O O O O O O O O O B-PER O  \n",
       "4  O O O O O O O O O O O O O O O O O O O B-LOC O ...  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = 'data/norne-nb-in5550-train.conllu.gz'\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "\n",
    "data = open_and_read_path(path)\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ea3517f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#num_classes = data[\"labels\"].nunique()\n",
    "num_classes = list(sorted(set(\" \".join(list(data['labels'])).split(\" \"))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8bcef75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Rus', 'har', 'en', 'klar', 'sosial', 'dimensjon', ';', 'man', 'drikker', 'for', 'å', 'signalisere', 'noe', 'om', 'hvem', 'man', 'er', ',', 'og', 'hvem', 'man', 'ikke', 'er', '.']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0        [Rus, har, en, klar, sosial, dimensjon, ;, man...\n",
       "1        [I, tillegg, skal, daglig, leder, ved, Miljøtr...\n",
       "2        [«, Angående, vår, nærmere, lovede, undersøkel...\n",
       "3        [-, I, verste, fall, kan, det, være, dødelig, ...\n",
       "4        [At, vi, i, det, hele, tatt, har, det, er, et,...\n",
       "                               ...                        \n",
       "18093                        [-, Bryne, er, et, søppellag]\n",
       "18094    [I, så, fall, har, Ulsrud, sikret, EM-medalje,...\n",
       "18095    [Men, det, vil, alltid, ,, som, jeg, har, sagt...\n",
       "18096    [Vi, vil, finne, løsninger, som, reduserer, ut...\n",
       "18097    [-, Jeg, kjørte, ikke, spesielt, bra, ,, jeg, ...\n",
       "Name: sentence, Length: 18098, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df, val_df = train_test_split(data,\n",
    "                                    train_size=0.7,\n",
    "                                    random_state=5550)\n",
    "\n",
    "\n",
    "train_texts = train_df[\"sentence\"].to_list()\n",
    "text_labels = train_df[\"labels\"].to_list()\n",
    "\n",
    "tokens = tokenizer(train_texts,\n",
    "          return_tensors=\"pt\",\n",
    "          padding=True,\n",
    "          truncation=True,\n",
    "          max_length=64)\n",
    "\n",
    "unk_index = embedding.get_index(\"[UNK]\")\n",
    "\n",
    "for document in data[\"sentence\"]:\n",
    "    print(document.split(\" \"))\n",
    "    break\n",
    "    \n",
    "data[\"sentence\"].str.split(\" \")\n",
    "#sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "198628a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbDataset(Dataset):\n",
    "    def __init__(self, data, embedding, label_vocab = None):\n",
    "\n",
    "        self.unk_index = embedding.get_index(\"[UNK]\")\n",
    "        self.sentences = [\n",
    "            [\n",
    "                embedding.get_index(token.lower(), default = self.unk_index)\n",
    "                for token in document\n",
    "            ] \n",
    "            for document in data[\"sentence\"].str.split(\" \")\n",
    "        ]\n",
    "            \n",
    "        unk_tokens = sum(token == self.unk_index for document in self.sentences for token in document)\n",
    "        n_tokens = sum(len(document) for document in self.sentences)\n",
    "        print(f\"Percentage of unknown tokens: {unk_tokens / n_tokens * 100.0:.2f}%\")\n",
    "        \n",
    "        self.label = list(data['labels'])\n",
    "        self.label_vocab = label_vocab if label_vocab is not None else list(sorted(set(\" \".join(self.label).split(\" \"))))\n",
    "        self.num_labels = len(self.label_vocab)\n",
    "        self.label_indexer = {i: n for n, i in enumerate(self.label_vocab)}\n",
    "        print(\"\\nLabel dictionary:\", self.label_indexer)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        current_tokens_sentence = self.sentences[index]\n",
    "        current_labels = self.label[index]\n",
    "\n",
    "        sentence = torch.LongTensor(current_tokens_sentence)\n",
    "\n",
    "        labels = []\n",
    "        for label in current_labels.split(\" \"):\n",
    "            labels.append(self.label_indexer[label])\n",
    "        \n",
    "        y = torch.LongTensor(labels)\n",
    "        return sentence, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sentences)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "56792c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import EmbDataset\n",
    "from useful_functions import CollateFunctor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "f19cb415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tPercentage of unknown tokens: 1.16%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dataset.EmbDataset"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = EmbDataset(train_df, embedding)\n",
    "type(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "a49f0ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_val_dataloader = DataLoader(train_dataset,\n",
    "                              batch_size=32,\n",
    "                              shuffle=True,\n",
    "                              drop_last=True,\n",
    "                              num_workers=1,\n",
    "                              collate_fn=CollateFunctor(embedding.get_index(\"[PAD]\"),\n",
    "                                                        64)\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "01ce4135",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/395 [00:04<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Caught TypeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py\", line 302, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 61, in fetch\n    return self.collate_fn(data)\n  File \"/Users/coco/Documents/Uio/IN5550/oblig/IN5550/oblig3/useful_functions.py\", line 72, in __call__\n    labels = torch.LongTensor(labels)\nTypeError: only integer tensors of a single element can be converted to an index\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [114], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sentence, y \u001b[38;5;129;01min\u001b[39;00m tqdm\u001b[38;5;241m.\u001b[39mtqdm(emb_val_dataloader):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(sentence)\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tqdm/std.py:1195\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1192\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1194\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1195\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1196\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1197\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1198\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    626\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    627\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 628\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    629\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    631\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    632\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1333\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1331\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1332\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_task_info[idx]\n\u001b[0;32m-> 1333\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1359\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1357\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_put_index()\n\u001b[1;32m   1358\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[0;32m-> 1359\u001b[0m     \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1360\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/_utils.py:543\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    540\u001b[0m     \u001b[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[1;32m    541\u001b[0m     \u001b[38;5;66;03m# instantiate since we don't know how to\u001b[39;00m\n\u001b[1;32m    542\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m--> 543\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "\u001b[0;31mTypeError\u001b[0m: Caught TypeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py\", line 302, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 61, in fetch\n    return self.collate_fn(data)\n  File \"/Users/coco/Documents/Uio/IN5550/oblig/IN5550/oblig3/useful_functions.py\", line 72, in __call__\n    labels = torch.LongTensor(labels)\nTypeError: only integer tensors of a single element can be converted to an index\n"
     ]
    }
   ],
   "source": [
    "for sentence, y in tqdm.tqdm(emb_val_dataloader):\n",
    "    print(sentence)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d45d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_df.iloc[0][\"sentence\"].split(\" \")), len(train_df.iloc[0][\"labels\"].split(\" \")))\n",
    "\n",
    "train_df.iloc[3][\"labels\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a68d1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332cc501",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f144d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_dataset[0][0]), len(train_dataset[0][1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "dac4576e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mapping_matrix_batched(offset_mapping, lengths, n_subwords: int, n_words: int):\n",
    "    mapping = torch.zeros(len(lengths), n_words, n_subwords)\n",
    "\n",
    "    for i_batch in range(len(lengths)):\n",
    "        current_word, remaining_len = 0, lengths[i_batch][0]\n",
    "\n",
    "        for i, (start, end) in enumerate(offset_mapping[i_batch]):\n",
    "            if start == end:\n",
    "                continue\n",
    "\n",
    "            mapping[i_batch, current_word, i] = 1\n",
    "            remaining_len -= end - start\n",
    "\n",
    "            if remaining_len <= 0 and current_word < len(lengths[i_batch]) - 1:\n",
    "                current_word += 1\n",
    "                remaining_len = lengths[i_batch][current_word]\n",
    "\n",
    "    return mapping\n",
    "\n",
    "offsets = train_dataset[0]\n",
    "#word_lengths = train_dataset[0]\n",
    "#subword_ids = train_dataset[0]\n",
    "#n_subwords = subword_ids.size(1)\n",
    "#n_words = max(len(words) for words in word_lengths)\n",
    "\n",
    "#offsets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b48deb83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                  | 0/2534 [00:00<?, ?it/s]2023-03-30 14:04:07.507855: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                  | 0/2534 [00:10<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "word_lengths = 0\n",
    "offsets = 0\n",
    "n_subwords = 0\n",
    "n_words = 0\n",
    "for input_ids, attention_mask, y, offset_mapping, word_length in tqdm.tqdm(train_iter):\n",
    "    offsets = offset_mapping\n",
    "    word_lengths = word_length\n",
    "    n_subwords = input_ids.size(1)\n",
    "    n_words = max(len(words) for words in word_lengths)\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "90f057ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 64, 64]),\n",
       " tensor([[[0., 1., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 1.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 1., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 1.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 1., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 1.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 1., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 1.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 1., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 1.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]]))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping_matrix = get_mapping_matrix_batched(offsets, word_lengths, n_subwords, n_words)\n",
    "mapping_matrix.shape, mapping_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9dee2d17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rus har en klar sosial dimensjon ; man drikker...</td>\n",
       "      <td>O O O O O O O O O O O O O O O O O O O O O O O O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I tillegg skal daglig leder ved Miljøtransport...</td>\n",
       "      <td>O O O O O O B-ORG I-ORG O O O O O O O O O O O ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>« Angående vår nærmere lovede undersøkelse på ...</td>\n",
       "      <td>O O O O O O O O O O O O O O O O O O O O O O O ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>- I verste fall kan det være dødelig hvis du s...</td>\n",
       "      <td>O O O O O O O O O O O O O O O B-PER O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>At vi i det hele tatt har det er et resultat a...</td>\n",
       "      <td>O O O O O O O O O O O O O O O O O O O B-LOC O ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  \\\n",
       "0  Rus har en klar sosial dimensjon ; man drikker...   \n",
       "1  I tillegg skal daglig leder ved Miljøtransport...   \n",
       "2  « Angående vår nærmere lovede undersøkelse på ...   \n",
       "3  - I verste fall kan det være dødelig hvis du s...   \n",
       "4  At vi i det hele tatt har det er et resultat a...   \n",
       "\n",
       "                                              labels  \n",
       "0    O O O O O O O O O O O O O O O O O O O O O O O O  \n",
       "1  O O O O O O B-ORG I-ORG O O O O O O O O O O O ...  \n",
       "2  O O O O O O O O O O O O O O O O O O O O O O O ...  \n",
       "3              O O O O O O O O O O O O O O O B-PER O  \n",
       "4  O O O O O O O O O O O O O O O O O O O B-LOC O ...  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = 'data/norne-nb-in5550-train.conllu.gz'\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "\n",
    "data = open_and_read_path(path)\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "405ce0e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "  File \"/Users/coco/Documents/Uio/IN5550/oblig/IN5550/oblig3/dataset.py\", line 9, in <module>\n",
      "    from useful_functions import encoder\n",
      "ImportError: cannot import name 'encoder' from 'useful_functions' (/Users/coco/Documents/Uio/IN5550/oblig/IN5550/oblig3/useful_functions.py)\n",
      "  0%|                                                     | 0/1 [00:04<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid(s) 34149) exited unexpectedly",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1120\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1119\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1120\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/queues.py:113\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    112\u001b[0m timeout \u001b[38;5;241m=\u001b[39m deadline \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[0;32m--> 113\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Empty\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/connection.py:262\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_readable()\n\u001b[0;32m--> 262\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/connection.py:429\u001b[0m, in \u001b[0;36mConnection._poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    428\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_poll\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout):\n\u001b[0;32m--> 429\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    430\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(r)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/connection.py:936\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    935\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 936\u001b[0m     ready \u001b[38;5;241m=\u001b[39m \u001b[43mselector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    937\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ready:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/selectors.py:416\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 416\u001b[0m     fd_event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/utils/data/_utils/signal_handling.py:66\u001b[0m, in \u001b[0;36m_set_SIGCHLD_handler.<locals>.handler\u001b[0;34m(signum, frame)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhandler\u001b[39m(signum, frame):\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;66;03m# This following call uses `waitid` with WNOHANG from C side. Therefore,\u001b[39;00m\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;66;03m# Python can still get and update the process status successfully.\u001b[39;00m\n\u001b[0;32m---> 66\u001b[0m     \u001b[43m_error_if_any_worker_fails\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m previous_handler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: DataLoader worker (pid 34149) exited unexpectedly with exit code 1. Details are lost due to multiprocessing. Rerunning with num_workers=0 may give better error trace.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [85], line 36\u001b[0m\n\u001b[1;32m     34\u001b[0m n_subwords \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     35\u001b[0m n_words \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 36\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m input_ids, attention_mask, y, offset_mapping, word_length \u001b[38;5;129;01min\u001b[39;00m tqdm\u001b[38;5;241m.\u001b[39mtqdm(train_iter):\n\u001b[1;32m     37\u001b[0m     input_ids \u001b[38;5;241m=\u001b[39m input_ids\n\u001b[1;32m     38\u001b[0m     offsets \u001b[38;5;241m=\u001b[39m offset_mapping\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tqdm/std.py:1195\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1192\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1194\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1195\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1196\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1197\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1198\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    626\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    627\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 628\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    629\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    631\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    632\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1316\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1313\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[1;32m   1315\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1316\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1317\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1318\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[1;32m   1319\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1282\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1278\u001b[0m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   1279\u001b[0m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   1280\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1281\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 1282\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1283\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m   1284\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1133\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(failed_workers) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1132\u001b[0m     pids_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mstr\u001b[39m(w\u001b[38;5;241m.\u001b[39mpid) \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m failed_workers)\n\u001b[0;32m-> 1133\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDataLoader worker (pid(s) \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m) exited unexpectedly\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(pids_str)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m   1134\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, queue\u001b[38;5;241m.\u001b[39mEmpty):\n\u001b[1;32m   1135\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: DataLoader worker (pid(s) 34149) exited unexpectedly"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "\n",
    "\n",
    "class FakeBERT:\n",
    "    def __init__(self, hidden_dim):\n",
    "        self.hidden_dim = hidden_dim\n",
    "    \n",
    "    def __call__(self, ids):\n",
    "        return torch.randn(ids.shape + (self.hidden_dim,))\n",
    "\n",
    "\n",
    "bert = FakeBERT(hidden_dim=4)\n",
    "\n",
    "sentences = [\"Let's start tokenizing\", \"What a VERYVERYVERY pretty sentence\", \"three\"]\n",
    "data = pd.DataFrame()\n",
    "data[\"sentence\"] = sentences\n",
    "data[\"labels\"] = [\"O O O\", \"O O O O O\", \"O\"]\n",
    "train_dataset = NotebookTokenDataset(data, tokenizer)\n",
    "\n",
    "train_iter = DataLoader(train_dataset,\n",
    "                        batch_size=3,\n",
    "                        shuffle=False,\n",
    "                        num_workers=1\n",
    "                        )\n",
    "input_ids = 0\n",
    "word_lengths = 0\n",
    "offsets = 0\n",
    "n_subwords = 0\n",
    "n_words = 0\n",
    "for input_ids, attention_mask, y, offset_mapping, word_length in tqdm.tqdm(train_iter):\n",
    "    input_ids = input_ids\n",
    "    offsets = offset_mapping\n",
    "    word_lengths = word_length\n",
    "    n_subwords = input_ids.size(1)\n",
    "    n_words = max(len(words) for words in word_lengths)\n",
    "    print(n_subwords, n_words)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "78f6534f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 15, 4])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 64, 15])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert = FakeBERT(hidden_dim=4)\n",
    "contextualized_embeddings = bert(input_ids)\n",
    "\n",
    "print(contextualized_embeddings.shape)\n",
    "\n",
    "mapping_matrix = get_mapping_matrix_batched(offsets, word_lengths, n_subwords, n_words)\n",
    "(mapping_matrix.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f0ee9061",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 64, 4]),\n",
       " tensor([[[ 0.1737,  0.4180,  0.6225,  0.6529],\n",
       "          [-0.0260,  1.3363,  0.3760, -2.1045],\n",
       "          [ 0.2998, -1.9301, -0.9482,  0.9698],\n",
       "          [ 0.0394,  1.5005,  0.5351,  1.5890],\n",
       "          [-3.0134, -0.4731, -0.0977,  0.0247],\n",
       "          [ 0.0339,  1.6950, -0.6612,  0.0854],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000]],\n",
       " \n",
       "         [[-0.3818,  0.3348,  0.1705, -0.3043],\n",
       "          [-0.1315, -0.9906, -0.9812, -0.1374],\n",
       "          [-0.0822, -1.2043,  0.8139, -0.0800],\n",
       "          [-1.9681, -0.7919, -0.7785,  1.8351],\n",
       "          [-0.7617, -1.7542, -0.6191, -0.7470],\n",
       "          [-0.4666,  0.6259,  0.3987,  1.9996],\n",
       "          [ 1.1421, -0.2364,  0.2285, -0.8764],\n",
       "          [ 0.6603, -0.3570,  0.3309,  1.3903],\n",
       "          [-1.4847,  0.0449, -0.9128, -0.8367],\n",
       "          [ 0.0381, -0.0034,  0.9796,  0.1820],\n",
       "          [ 0.9651, -0.0159, -0.0273, -1.3356],\n",
       "          [-0.2898, -0.4832, -0.5614,  0.8029],\n",
       "          [ 0.3772, -1.2764,  0.7408,  0.1574],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000]],\n",
       " \n",
       "         [[-0.0595, -0.1999, -0.3506,  1.4107],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000]]]))"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summ = torch.einsum('bij, bjk -> bik', mapping_matrix, contextualized_embeddings)\n",
    "res = summ / torch.clamp(torch.sum(mapping_matrix, dim = 2, keepdim = True), 1)\n",
    "res.shape, res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bebaa021",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 15, 4])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding = tokenizer(sentences, padding=True, return_offsets_mapping=True)\n",
    "subword_ids = torch.tensor(encoding.input_ids)\n",
    "offsets = encoding.offset_mapping\n",
    "\n",
    "bert = FakeBERT(hidden_dim=4)\n",
    "contextualized_embeddings = bert(subword_ids)\n",
    "\n",
    "contextualized_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d5f6aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, label_vocab = None):\n",
    "        \n",
    "        self.max_length = 64\n",
    "        \n",
    "        self.train_texts = data[\"sentence\"].to_list()\n",
    "        self.labels = list(data[\"labels\"])\n",
    "        \n",
    "        self.encoding = tokenizer(self.train_texts,\n",
    "                                 padding = True,\n",
    "                                 truncation = True,\n",
    "                                 return_offsets_mapping = True,\n",
    "                                 max_length = self.max_length)\n",
    "        \n",
    "        self.input_ids = torch.tensor(self.encoding.input_ids)\n",
    "        self.attention_mask = torch.tensor(self.encoding[\"attention_mask\"])\n",
    "        \n",
    "        self.offsets = self.encoding.offset_mapping\n",
    "        self.word_lengths = [[len(word) for word in sentence.split()] for sentence in self.train_texts]\n",
    "\n",
    "        self.label_vocab = label_vocab if label_vocab is not None else list(sorted(set(\" \".join(self.labels).split(\" \"))))\n",
    "        self.num_labels = len(self.label_vocab)\n",
    "        self.label_indexer = {i: n for n, i in enumerate(self.label_vocab)}\n",
    "        print(\"\\nLabel dictionary:\", self.label_indexer)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        current_input_ids = self.input_ids[index]\n",
    "        current_attention_mask = self.attention_mask[index]\n",
    "\n",
    "        input_ids = torch.LongTensor(current_input_ids)\n",
    "        attention_mask = torch.LongTensor(current_attention_mask)\n",
    "\n",
    "        \n",
    "        def pad(l, content, width):\n",
    "            l.extend([content] * (width - len(l)))\n",
    "            return l\n",
    "            \n",
    "        current_labels = self.labels[index]\n",
    "        value = self.label_indexer[\"O\"]\n",
    "        labels = []\n",
    "        for label in current_labels.split(\" \"):\n",
    "            labels.append(self.label_indexer[label])\n",
    "        labels = pad(labels, value, self.max_length)\n",
    "        \n",
    "        y = torch.LongTensor(labels)\n",
    "        \n",
    "        offset_mapping = self.offsets[index]\n",
    "        word_length = self.word_lengths[index]\n",
    "        word_length = pad(word_length, 0, self.max_length)\n",
    "        \n",
    "        #mapping_matrix_info = {\"offset_mapping\" : offset_mapping,\"word_length\" : word_length}\n",
    "        \n",
    "        \n",
    "        return input_ids, attention_mask, y, offset_mapping, word_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.train_texts)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "956eda88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  0],\n",
       "        [ 0,  9],\n",
       "        [10, 16],\n",
       "        [17, 22],\n",
       "        [23, 25],\n",
       "        [26, 27],\n",
       "        [28, 31],\n",
       "        [32, 35],\n",
       "        [35, 37],\n",
       "        [37, 38],\n",
       "        [38, 42],\n",
       "        [43, 45],\n",
       "        [46, 48],\n",
       "        [48, 51],\n",
       "        [52, 55],\n",
       "        [55, 57],\n",
       "        [57, 58],\n",
       "        [59, 61],\n",
       "        [61, 62],\n",
       "        [63, 64],\n",
       "        [64, 65],\n",
       "        [65, 67],\n",
       "        [68, 70],\n",
       "        [71, 74],\n",
       "        [75, 76],\n",
       "        [76, 77],\n",
       "        [78, 81],\n",
       "        [82, 83],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0],\n",
       "        [ 0,  0]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "off = train_dataset[0][3]\n",
    "torch.LongTensor(off)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "a6375e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df = train_test_split(data,\n",
    "                                    train_size=0.7,\n",
    "                                    random_state=5550)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "ee9aadb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import NotebookTokenDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "f12be36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = NotebookTokenDataset(train_df, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "100d4afd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenized sentence:  tensor([  101,  1697, 14319,  7661, 21718,   178, 11850, 13354,  2180,   118,\n",
      "         8144,  1120,  1110,  7609,  1155,  3121,  1181,  5871,  1197,   191,\n",
      "        28200,  3740,  4035,  3687,   170,  1964,  3066,   119,   102,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0])\n",
      "\n",
      "attention mask:  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n",
      "labels:  tensor([16,  6, 14, 16, 16, 16,  0, 16, 16, 16, 16, 16, 16, 16, 16,  2, 16, 16,\n",
      "        16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
      "        16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
      "        16, 16, 16, 16, 16, 16, 16, 16, 16, 16])\n",
      "\n",
      "Offsets:  tensor([[ 0,  0],\n",
      "        [ 0,  9],\n",
      "        [10, 16],\n",
      "        [17, 22],\n",
      "        [23, 25],\n",
      "        [26, 27],\n",
      "        [28, 31],\n",
      "        [32, 35],\n",
      "        [35, 37],\n",
      "        [37, 38],\n",
      "        [38, 42],\n",
      "        [43, 45],\n",
      "        [46, 48],\n",
      "        [48, 51],\n",
      "        [52, 55],\n",
      "        [55, 57],\n",
      "        [57, 58],\n",
      "        [59, 61],\n",
      "        [61, 62],\n",
      "        [63, 64],\n",
      "        [64, 65],\n",
      "        [65, 67],\n",
      "        [68, 70],\n",
      "        [71, 74],\n",
      "        [75, 76],\n",
      "        [76, 77],\n",
      "        [78, 81],\n",
      "        [82, 83],\n",
      "        [ 0,  0],\n",
      "        [ 0,  0],\n",
      "        [ 0,  0],\n",
      "        [ 0,  0],\n",
      "        [ 0,  0],\n",
      "        [ 0,  0],\n",
      "        [ 0,  0],\n",
      "        [ 0,  0],\n",
      "        [ 0,  0],\n",
      "        [ 0,  0],\n",
      "        [ 0,  0],\n",
      "        [ 0,  0],\n",
      "        [ 0,  0],\n",
      "        [ 0,  0],\n",
      "        [ 0,  0],\n",
      "        [ 0,  0],\n",
      "        [ 0,  0],\n",
      "        [ 0,  0],\n",
      "        [ 0,  0],\n",
      "        [ 0,  0],\n",
      "        [ 0,  0],\n",
      "        [ 0,  0],\n",
      "        [ 0,  0],\n",
      "        [ 0,  0],\n",
      "        [ 0,  0],\n",
      "        [ 0,  0],\n",
      "        [ 0,  0],\n",
      "        [ 0,  0],\n",
      "        [ 0,  0],\n",
      "        [ 0,  0],\n",
      "        [ 0,  0],\n",
      "        [ 0,  0],\n",
      "        [ 0,  0],\n",
      "        [ 0,  0],\n",
      "        [ 0,  0],\n",
      "        [ 0,  0]])\n",
      "\n",
      "Word length:  tensor([ 9,  6,  5,  2,  1,  3, 10,  2,  5,  6,  3,  4,  2,  3,  2,  3,  1,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n"
     ]
    }
   ],
   "source": [
    "print(\"tokenized sentence: \", train_dataset[0][0])\n",
    "print(\"\\nattention mask: \", train_dataset[0][1])\n",
    "print(\"\\nlabels: \", train_dataset[0][2])\n",
    "print(\"\\nOffsets: \", train_dataset[0][3])\n",
    "print(\"\\nWord length: \", train_dataset[0][4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "0c5242ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12668\n",
      "5\n",
      "64 64 64 64 64\n",
      "\n",
      "\n",
      "5\n",
      "64 64 64 64 64\n",
      "\n",
      "\n",
      "5\n",
      "64 64 64 64 64\n",
      "\n",
      "\n",
      "5\n",
      "64 64 64 64 64\n",
      "\n",
      "\n",
      "5\n",
      "64 64 64 64 64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataset))\n",
    "\n",
    "for i in range(5):\n",
    "    print(len(train_dataset[i]))\n",
    "    print(len(train_dataset[i][0]), len(train_dataset[i][1]), len(train_dataset[i][2]), len(train_dataset[i][3]), len(train_dataset[i][4]))\n",
    "    print(\"\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "7b98e5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "train_iter = DataLoader(train_dataset,\n",
    "                        batch_size=5,\n",
    "                        shuffle=False,\n",
    "                        num_workers=1\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ed92e0df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                  | 0/2534 [00:00<?, ?it/s]2023-03-30 13:51:30.807441: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  0],\n",
      "        [ 0,  9],\n",
      "        [10, 16],\n",
      "        [17, 22],\n",
      "        [23, 25],\n",
      "        [26, 27],\n",
      "        [28, 31],\n",
      "        [32, 35],\n",
      "        [35, 37],\n",
      "        [37, 38],\n",
      "        [38, 42],\n",
      "        [43, 45],\n",
      "        [46, 48],\n",
      "        [48, 51],\n",
      "        [52, 55],\n",
      "        [55, 57],\n",
      "        [57, 58],\n",
      "        [59, 61],\n",
      "        [61, 62],\n",
      "        [63, 64],\n",
      "        [64, 65],\n",
      "        [65, 67],\n",
      "        [68, 70],\n",
      "        [71, 74],\n",
      "        [75, 76],\n",
      "        [76, 77],\n",
      "        [78, 81],\n",
      "        [82, 83],\n",
      "        [ 0,  0],\n",
      "        [ 0,  0],\n",
      "        [ 0,  0],\n",
      "        [ 0,  0],\n",
      "        [ 0,  0],\n",
      "        [ 0,  0],\n",
      "        [ 0,  0],\n",
      "        [ 0,  0],\n",
      "        [ 0,  0],\n",
      "        [ 0,  0],\n",
      "        [ 0,  0],\n",
      "        [ 0,  0],\n",
      "        [ 0,  0],\n",
      "        [ 0,  0],\n",
      "        [ 0,  0],\n",
      "        [ 0,  0],\n",
      "        [ 0,  0],\n",
      "        [ 0,  0],\n",
      "        [ 0,  0],\n",
      "        [ 0,  0],\n",
      "        [ 0,  0],\n",
      "        [ 0,  0],\n",
      "        [ 0,  0],\n",
      "        [ 0,  0],\n",
      "        [ 0,  0],\n",
      "        [ 0,  0],\n",
      "        [ 0,  0],\n",
      "        [ 0,  0],\n",
      "        [ 0,  0],\n",
      "        [ 0,  0],\n",
      "        [ 0,  0],\n",
      "        [ 0,  0],\n",
      "        [ 0,  0],\n",
      "        [ 0,  0],\n",
      "        [ 0,  0],\n",
      "        [ 0,  0]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                  | 0/2534 [00:13<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "for input_ids, attention_mask, y, offset_mapping, word_length in tqdm.tqdm(train_iter):\n",
    "    print(input_ids)\n",
    "    print(\"\\n\")\n",
    "    print(attention_mask)\n",
    "    print(\"\\n\")\n",
    "    print(y)\n",
    "    print(\"\\n\")\n",
    "    print(offset_mapping)\n",
    "    print(\"\\n\")\n",
    "    print(word_length)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2e124eb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                  | 0/2534 [00:00<?, ?it/s]2023-03-30 13:51:44.654267: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 9,  6,  5,  2,  1,  3, 10,  2,  5,  6,  3,  4,  2,  3,  2,  3,  1,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "        [ 2,  3,  6,  5,  2,  5, 10,  3,  1,  5,  6,  1,  3,  3,  4,  3,  4, 11,\n",
      "          1,  3,  3,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "        [ 4, 13,  3,  6,  2,  1,  6,  8,  6,  2,  1,  6,  9,  6,  2,  1,  3,  9,\n",
      "          5,  6,  2,  1,  6,  4,  6,  2,  2,  7,  8,  6,  2,  1,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "        [ 1,  1,  5,  3,  2,  5,  6,  6,  2,  8,  5,  6,  1,  3,  3,  2,  4,  7,\n",
      "          1,  6,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "        [ 1,  3,  2,  2,  3,  4,  2,  3,  5,  2,  1,  3,  1,  5,  6,  4,  3,  1,\n",
      "          4,  6,  1,  2,  5,  2,  5,  3,  5, 10,  7,  1,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                  | 0/2534 [00:11<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "for input_ids, attention_mask, y, offset_mapping, word_length in tqdm.tqdm(train_iter):\n",
    "    print(word_length)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7477994b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                  | 0/2534 [00:00<?, ?it/s]2023-03-30 13:51:56.250304: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64 64 64 64 64\n",
      "\t\t\tLengths are the same: True\n",
      "\t\t\tBatch size is correct: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                  | 0/2534 [00:11<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "for input_ids, attention_mask, y, offset_mapping, word_length in tqdm.tqdm(train_iter):\n",
    "    #print(offset_mapping)\n",
    "    print(len(input_ids[0]), len(attention_mask[0]), len(y[0]), len(offset_mapping[0]), len(word_length[0]))\n",
    "    print(\"\\t\\t\\tLengths are the same:\", len(input_ids[0]) == len(attention_mask[0]) == len(y[0]) == len(offset_mapping[0]) == len(word_length[0]))\n",
    "    print(\"\\t\\t\\tBatch size is correct:\", len(input_ids) == 5)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "36e725bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'TokenDataset' on <module '__main__' (built-in)>\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [30], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      2\u001b[0m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTOKENIZERS_PARALLELISM\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfalse\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_iter\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py:435\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator\n\u001b[1;32m    434\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 435\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py:381\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    380\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_worker_number_rationality()\n\u001b[0;32m--> 381\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_MultiProcessingDataLoaderIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1034\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[0;34m(self, loader)\u001b[0m\n\u001b[1;32m   1027\u001b[0m w\u001b[38;5;241m.\u001b[39mdaemon \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1028\u001b[0m \u001b[38;5;66;03m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[1;32m   1029\u001b[0m \u001b[38;5;66;03m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[1;32m   1030\u001b[0m \u001b[38;5;66;03m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[1;32m   1031\u001b[0m \u001b[38;5;66;03m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[1;32m   1032\u001b[0m \u001b[38;5;66;03m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[1;32m   1033\u001b[0m \u001b[38;5;66;03m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[0;32m-> 1034\u001b[0m \u001b[43mw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1035\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_queues\u001b[38;5;241m.\u001b[39mappend(index_queue)\n\u001b[1;32m   1036\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_workers\u001b[38;5;241m.\u001b[39mappend(w)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _current_process\u001b[38;5;241m.\u001b[39m_config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemon\u001b[39m\u001b[38;5;124m'\u001b[39m), \\\n\u001b[1;32m    119\u001b[0m        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemonic processes are not allowed to have children\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    120\u001b[0m _cleanup()\n\u001b[0;32m--> 121\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sentinel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen\u001b[38;5;241m.\u001b[39msentinel\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;66;03m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[0;32m--> 224\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mProcess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/context.py:284\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    282\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[1;32m    283\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpopen_spawn_posix\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Popen\n\u001b[0;32m--> 284\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/popen_spawn_posix.py:32\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, process_obj):\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fds \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 32\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/popen_fork.py:19\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinalizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_launch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/multiprocessing/popen_spawn_posix.py:62\u001b[0m, in \u001b[0;36mPopen._launch\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msentinel \u001b[38;5;241m=\u001b[39m parent_r\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(parent_w, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m, closefd\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m---> 62\u001b[0m         \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetbuffer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     64\u001b[0m     fds_to_close \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#import os\n",
    "#os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "next(enumerate(train_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "02d04b1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df.iloc[0][\"sentence\"].split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e5214bc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4,\n",
       " (tensor([  101, 12786, 24181,  1179, 16412,  1162,  3084,  2083,  3084,   188,\n",
       "          18974,  1116,  3697,  6834, 18408,  1111,   251,  2080,  1162, 27629,\n",
       "          21270,  1424,   117,  1441,  1260,  1204,  1119,  1513, 24181,  1179,\n",
       "            180, 12148, 11769,  3491,  1818, 14554,  1116,   178,  3084,  1204,\n",
       "           1137,  1181,   131,   102,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "          16, 16, 16, 16]),\n",
       "  {'offset_mapping': [(0, 0),\n",
       "    (0, 2),\n",
       "    (3, 5),\n",
       "    (5, 6),\n",
       "    (7, 12),\n",
       "    (12, 13),\n",
       "    (14, 16),\n",
       "    (16, 19),\n",
       "    (20, 22),\n",
       "    (23, 24),\n",
       "    (24, 27),\n",
       "    (27, 28),\n",
       "    (29, 34),\n",
       "    (34, 36),\n",
       "    (36, 39),\n",
       "    (40, 43),\n",
       "    (44, 45),\n",
       "    (46, 50),\n",
       "    (50, 51),\n",
       "    (52, 54),\n",
       "    (54, 56),\n",
       "    (56, 58),\n",
       "    (59, 60),\n",
       "    (61, 64),\n",
       "    (65, 67),\n",
       "    (67, 68),\n",
       "    (69, 71),\n",
       "    (71, 73),\n",
       "    (74, 76),\n",
       "    (76, 77),\n",
       "    (78, 79),\n",
       "    (79, 82),\n",
       "    (83, 85),\n",
       "    (85, 87),\n",
       "    (87, 89),\n",
       "    (89, 93),\n",
       "    (93, 94),\n",
       "    (95, 96),\n",
       "    (97, 99),\n",
       "    (99, 100),\n",
       "    (101, 103),\n",
       "    (103, 104),\n",
       "    (105, 106),\n",
       "    (0, 0),\n",
       "    (0, 0),\n",
       "    (0, 0),\n",
       "    (0, 0),\n",
       "    (0, 0),\n",
       "    (0, 0),\n",
       "    (0, 0),\n",
       "    (0, 0),\n",
       "    (0, 0),\n",
       "    (0, 0),\n",
       "    (0, 0),\n",
       "    (0, 0),\n",
       "    (0, 0),\n",
       "    (0, 0),\n",
       "    (0, 0),\n",
       "    (0, 0),\n",
       "    (0, 0),\n",
       "    (0, 0),\n",
       "    (0, 0),\n",
       "    (0, 0),\n",
       "    (0, 0)],\n",
       "   'word_length': [2,\n",
       "    3,\n",
       "    6,\n",
       "    5,\n",
       "    2,\n",
       "    5,\n",
       "    10,\n",
       "    3,\n",
       "    1,\n",
       "    5,\n",
       "    6,\n",
       "    1,\n",
       "    3,\n",
       "    3,\n",
       "    4,\n",
       "    3,\n",
       "    4,\n",
       "    11,\n",
       "    1,\n",
       "    3,\n",
       "    3,\n",
       "    1]}))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset[1]), train_dataset[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "id": "604f86b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 64, tensor(29), 17, 17)"
      ]
     },
     "execution_count": 588,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset[0][0]), len(train_dataset[0][1]), sum(train_dataset[0][1] == 1), len(train_dataset[0][2]), len(train_dataset[0][3][\"word_length\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230df2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(sorted(set(\" \".join(text_labels).split(\" \"))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a74f6043",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df = train_test_split(data,\n",
    "                                    train_size=0.7,\n",
    "                                    random_state=5550)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "\n",
    "\n",
    "train_texts = train_df[\"sentence\"].to_list()\n",
    "text_labels = train_df[\"labels\"].to_list()\n",
    "text_labels = list(sorted(set(\" \".join(text_labels).split(\" \"))))\n",
    "num_classes = len(text_labels)\n",
    "\n",
    "encoding = tokenizer(train_texts,\n",
    "                     padding = True,\n",
    "                     truncation = True,\n",
    "                     return_offsets_mapping = True,\n",
    "                     max_length = 64)\n",
    "\n",
    "subword_ids = torch.tensor(encoding.input_ids)\n",
    "offsets = torch.tensor(encoding.offset_mapping)\n",
    "attention_mask = torch.tensor(encoding.attention_mask)\n",
    "\n",
    "word_lengths = [[len(word) for word in sentence.split()] for sentence in train_texts]\n",
    "n_subwords = subword_ids.size(1)\n",
    "n_words = max(len(words) for words in word_lengths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "561a1c68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Label dictionary: {'B-DRV': 0, 'B-EVT': 1, 'B-GPE_LOC': 2, 'B-GPE_ORG': 3, 'B-LOC': 4, 'B-ORG': 5, 'B-PER': 6, 'B-PROD': 7, 'I-DRV': 8, 'I-EVT': 9, 'I-GPE_LOC': 10, 'I-GPE_ORG': 11, 'I-LOC': 12, 'I-ORG': 13, 'I-PER': 14, 'I-PROD': 15, 'O': 16}\n"
     ]
    }
   ],
   "source": [
    "from torch.utils import data\n",
    "label_vocab = None\n",
    "\n",
    "train_texts = train_df[\"sentence\"].to_list()\n",
    "labels = list(train_df[\"labels\"])\n",
    "\n",
    "encoding = tokenizer(train_texts,\n",
    "                         padding = True,\n",
    "                         truncation = True,\n",
    "                         return_offsets_mapping = True,\n",
    "                         max_length = 64)\n",
    "\n",
    "input_ids = torch.tensor(encoding.input_ids)\n",
    "attention_mask = torch.tensor(encoding[\"attention_mask\"])\n",
    "\n",
    "offsets = encoding.offset_mapping\n",
    "word_lengths = [[len(word) for word in sentence.split()] for sentence in train_texts]\n",
    "\n",
    "label_vocab = label_vocab if label_vocab is not None else list(sorted(set(\" \".join(labels).split(\" \"))))\n",
    "num_labels = len(label_vocab)\n",
    "label_indexer = {i: n for n, i in enumerate(label_vocab)}\n",
    "print(\"\\nLabel dictionary:\", label_indexer)\n",
    "\n",
    "\n",
    "new_labels = []\n",
    "for label in labels:\n",
    "    new_label_row = []\n",
    "    for lab in label.split(\" \"):\n",
    "        new_label_row.append(label_indexer[lab])\n",
    "    new_labels.append(torch.LongTensor(new_label_row))\n",
    "    \n",
    "\n",
    "y = new_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "8b734d51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([16,  6, 14, 16, 16, 16,  0, 16, 16, 16, 16, 16, 16, 16, 16,  2, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16]),\n",
       " tensor([ 6, 14, 16, 16, 16, 16,  6, 14, 16, 16, 16,  6, 14, 16, 16, 16,  6, 14,\n",
       "         14, 16, 16, 16,  6, 14, 16, 16, 16,  6, 14, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16,  6, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16,  2, 16,  6, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16,  6, 16, 16]),\n",
       " tensor([ 6, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16,  5, 16, 16, 16, 16, 16, 16, 16,  5, 16,\n",
       "         16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16]),\n",
       " tensor([16, 16,  4, 16, 16, 16, 16, 16, 16,  2, 16, 16, 16,  4, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16,  6, 14, 16, 16, 16, 16, 16, 16, 16, 16,  6, 16, 16, 16, 16,\n",
       "          2, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16,  2, 16, 16, 16, 16, 16,  2, 16]),\n",
       " tensor([16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,  5,\n",
       "         16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16,  6, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16,  6, 16,  6, 16,  6, 16, 16, 16, 16, 16,  6, 16, 16,  6, 16, 16, 16,\n",
       "         16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16]),\n",
       " tensor([16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16,  6, 16,  6, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16,  0, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16,  6, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([ 5, 16,  5, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16]),\n",
       " tensor([ 2, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16,  2, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16,  6, 14, 16]),\n",
       " tensor([16, 16, 16,  6, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16,  6, 14, 16,  6, 14, 16]),\n",
       " tensor([ 5, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16,  0, 16]),\n",
       " tensor([ 5, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16]),\n",
       " tensor([ 6, 16, 16, 16, 16, 16,  4, 12, 12, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16,  7, 16,  7, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,  4, 16,\n",
       "          2, 16, 16, 16, 16, 16,  0, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16,  3, 16, 16,  0, 16,  2, 16]),\n",
       " tensor([16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([ 2, 16,  5, 16, 16]),\n",
       " tensor([16, 16, 16, 16,  4, 16,  2, 16, 16, 16, 16,  2, 16, 16, 16, 16, 16, 16,\n",
       "          2, 16,  2, 16, 16, 16, 16, 16, 16, 16,  2, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16,  0,  8, 16, 16, 16, 16, 16, 16, 16, 16, 16,  3,\n",
       "         16,  3, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,  2, 16, 16]),\n",
       " tensor([ 6, 16, 16, 16, 16, 16, 16, 16,  7, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16,  7, 15, 15, 15, 16, 16, 16, 16, 16, 16, 16,\n",
       "          2, 16,  2, 16, 16, 16]),\n",
       " tensor([16,  6, 14, 16,  2, 16,  6, 14, 16,  2, 16,  6, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16, 16,  2, 10, 16, 16,  2, 16, 16, 16]),\n",
       " tensor([16,  7, 15, 15, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16]),\n",
       " tensor([16, 16, 16, 16]),\n",
       " tensor([ 6, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16,  5, 13]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,  6,\n",
       "         16]),\n",
       " tensor([16, 16,  6, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,  2, 16]),\n",
       " tensor([16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16,  4, 12, 16]),\n",
       " tensor([16,  5, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,  5, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16,  6, 14, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,  4, 16, 16, 16, 16, 16,\n",
       "         16, 16,  5, 16,  5, 16, 16, 16, 16]),\n",
       " tensor([ 6, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,  5, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16,  6, 14, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16, 16, 16, 16, 16,  6, 16]),\n",
       " tensor([16, 16, 16, 16,  6, 14, 16, 16, 16, 16, 16, 16, 16, 16, 16,  2, 10, 16]),\n",
       " tensor([16, 16, 16, 16,  7, 16, 16, 16, 16, 16, 16, 16, 16,  6, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16,  6, 16, 16,  5, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16,  6, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,  7, 16]),\n",
       " tensor([16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16,  7, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16,  7, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16]),\n",
       " tensor([ 4, 12, 16,  4, 16,  4, 12, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16]),\n",
       " tensor([ 6, 14, 16, 16, 16, 16, 16, 16, 16,  7, 15, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16,  5]),\n",
       " tensor([16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16,  2, 16, 16,  2, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16,  0, 16, 16, 16, 16]),\n",
       " tensor([ 5, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16]),\n",
       " tensor([16, 16]),\n",
       " tensor([ 5, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16,  0, 16, 16, 16]),\n",
       " tensor([16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16,  2, 10, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16,  7, 16]),\n",
       " tensor([16,  4, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16]),\n",
       " tensor([16,  6, 14, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([ 6, 16, 16, 16]),\n",
       " tensor([ 5, 13, 13, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16,  4, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16,  5, 16,  6, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "          5, 13, 13, 13, 16,  5, 16, 16,  6, 14, 16, 16, 16,  5, 16]),\n",
       " tensor([ 5, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,  2, 16, 16,\n",
       "          2, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16,  0, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16,  7, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16,  5, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16,  7, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16]),\n",
       " tensor([16, 16,  5, 16, 16, 16, 16,  6, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16,  6, 14, 16, 16, 16, 16, 16, 16, 16,  5, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16,  5, 16,  5, 13, 16,  2, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16,  2, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "          7, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16,  0,  8,  7, 15, 15, 15, 15, 15, 15, 15, 15, 16,\n",
       "         16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,  6, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16,  5, 13, 16, 16, 16, 16, 16, 16,  2, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16,  7, 15, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16,  0, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,  6, 14, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16,  2, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16,  6, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16,  2, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16,  5, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,  6, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16]),\n",
       " tensor([ 6, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,  0, 16, 16,  5, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16, 16, 16,  2, 16]),\n",
       " tensor([16, 16, 16, 16, 16,  4, 12, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16,  5, 16, 16, 16, 16, 16, 16, 16, 16, 16,  6, 16]),\n",
       " tensor([ 5, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16,  6, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16,  6, 16, 16, 16]),\n",
       " tensor([ 6, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,  2, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16]),\n",
       " tensor([ 6, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16,  2, 16]),\n",
       " tensor([16, 16]),\n",
       " tensor([16,  2, 10, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16]),\n",
       " tensor([ 5, 16, 16,  6, 14, 16, 16, 16,  2, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,  6, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16,  6, 14, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,  2, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16,  2, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([ 6, 14, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,  6, 16, 16,\n",
       "         16, 16,  5, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16,  1, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16,  5, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16,  0, 16, 16, 16, 16,  6, 14, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16,  2, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16,  5]),\n",
       " tensor([16, 16, 16, 16,  7, 15, 15, 15, 15, 15, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([ 5, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16,  6, 14, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16,  6, 16, 16, 16, 16, 16, 16, 16,  2, 16,  2, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16]),\n",
       " tensor([ 5, 16,  5, 16, 16, 16, 16]),\n",
       " tensor([ 0, 16]),\n",
       " tensor([16, 16, 16,  7, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16,  6, 16,  6, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16,  2, 16, 16, 16, 16, 16,  6, 16,  6, 16]),\n",
       " tensor([ 6, 14, 16,  2, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16,  6, 14, 14, 16,  5, 13, 13, 16, 16, 16, 16,  0, 16, 16, 16, 16, 16,\n",
       "         16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16,  6, 14, 14, 16]),\n",
       " tensor([16,  6, 14, 14, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16]),\n",
       " tensor([ 6, 16, 16, 16, 16, 16,  7, 15, 15, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,  6, 14, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,  4, 16]),\n",
       " tensor([16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([ 6, 14, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16,  7, 15, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([ 6, 14, 16,  5, 16, 16]),\n",
       " tensor([ 6, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([ 6, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,  6, 16]),\n",
       " tensor([16, 16,  6, 14, 14]),\n",
       " tensor([16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16,  6, 14, 16, 16, 16, 16, 16,  6, 14, 16, 16, 16, 16, 16, 16, 16,\n",
       "          6, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16,  6, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16]),\n",
       " tensor([16, 16, 16]),\n",
       " tensor([ 7, 16, 16, 16, 16,  7, 15, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16]),\n",
       " tensor([16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16,  6, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16,  5, 13, 16, 16, 16,  5, 13, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,  5]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16,  2, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16,  0,  8, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16]),\n",
       " tensor([16, 16,  5, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16,  5,  0, 16,  2, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16]),\n",
       " tensor([16, 16, 16,  6, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16]),\n",
       " tensor([16, 16, 16, 16,  6, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16,  3, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16,  5, 16, 16, 16, 16, 16,  0, 16, 16, 16,  5,  6, 14, 16, 16, 16, 16,\n",
       "         16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16,  6, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([ 6, 14, 16, 16, 16, 16, 16,  5, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16,  5, 13, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16,  5, 16,  5, 16, 16, 16, 16, 16, 16, 16, 16, 16,  5, 16, 16,\n",
       "         16, 16]),\n",
       " tensor([16, 16, 16, 16,  5, 13, 13, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16,  2, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16,  6, 14, 14, 16,  5]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,  2,\n",
       "         16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([ 6, 14, 14, 16, 16, 16, 16,  6, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16,  6, 14, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16,  5, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16,  2, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16, 16, 16,  2, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16,  6, 14, 14, 16, 16, 16,  5, 13, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16]),\n",
       " tensor([16]),\n",
       " tensor([16, 16, 16, 16,  2, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([ 4, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,  5, 16,  6, 14,\n",
       "         16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,  7, 15,\n",
       "         16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16,  0, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16,  7, 15, 15, 15, 15, 16, 16, 16, 16, 16,  7, 15, 15, 16, 16]),\n",
       " tensor([16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16]),\n",
       " tensor([ 5, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16,  0,  8, 16,  2, 16]),\n",
       " tensor([16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16,  6, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16,  2, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,  5,\n",
       "         16,  6, 14, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16,  5, 13, 13, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([ 6, 14, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,  4, 12, 12, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,  0, 16]),\n",
       " tensor([ 5, 16,  5, 16, 16,  0,  8, 16]),\n",
       " tensor([16, 16, 16, 16,  4, 12, 12, 12, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16]),\n",
       " tensor([16, 16, 16, 16,  2, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([ 5, 13, 16,  5, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16,  6, 14, 16,  6, 14, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16,  6, 16, 16,  6, 16, 16, 16, 16, 16, 16,  4, 12, 12,\n",
       "         12, 16,  2, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,  4, 16, 16, 16, 16, 16,\n",
       "         16, 16]),\n",
       " tensor([ 0, 16,  2]),\n",
       " tensor([16, 16,  5]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16,  5, 13, 13, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16,  6, 16, 16, 16,  6, 14, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,  5, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([ 6, 16, 16, 16, 16, 16, 16, 16, 16,  2, 16, 16]),\n",
       " tensor([16,  5, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16,  6, 16,  5, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16,  7, 15, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16]),\n",
       " tensor([16, 16, 16,  6, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16,  3, 16, 16, 16, 16, 16,  0, 16,\n",
       "          2, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16]),\n",
       " tensor([ 6, 16, 16, 16, 16, 16,  5, 13, 13, 16,  2, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16]),\n",
       " tensor([16, 16, 16,  3, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16]),\n",
       " tensor([16, 16, 16, 16, 16,  1, 16,  1, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16,  5, 16, 16, 16, 16, 16,  2, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16,  7, 15, 15, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16,  7, 16, 16, 16,  5, 13, 13, 16]),\n",
       " tensor([16, 16,  5, 16, 16, 16, 16, 16,  5, 13, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16]),\n",
       " tensor([ 6, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16]),\n",
       " tensor([16, 16, 16,  4, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16,  2, 16]),\n",
       " tensor([16, 16]),\n",
       " tensor([ 6, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16,  4, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16,  5, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([ 6, 14, 16, 16, 16, 16, 16, 16,  2, 16, 16, 16]),\n",
       " tensor([16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,  5, 13, 13, 16,  5, 16, 16,\n",
       "         16, 16, 16,  6, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([ 6, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16,  2]),\n",
       " tensor([16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([ 6, 14, 14, 16]),\n",
       " tensor([16, 16,  5, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16,  6, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16,  7, 15, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "          5, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16,  6, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16,  2, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16,  6, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16,  6, 14]),\n",
       " tensor([16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16,  2, 10, 16,  2, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16]),\n",
       " tensor([16,  5, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,  6, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,  4, 16]),\n",
       " tensor([16,  6, 14, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16]),\n",
       " tensor([ 6, 14, 14, 16, 16, 16,  5, 13, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16]),\n",
       " tensor([ 6, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([ 6, 14, 16,  6, 16, 16, 16, 16, 16,  6, 14, 16,  6, 16]),\n",
       " tensor([ 5, 16,  6, 14, 14, 16, 16, 16, 16,  1, 16, 16, 16, 16,  3, 16]),\n",
       " tensor([16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16,  6, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,  5, 16, 16, 16,\n",
       "         16]),\n",
       " tensor([16, 16, 16, 16,  6, 16, 16, 16, 16, 16,  5, 13, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16, 16, 16,  1, 16,  4, 16]),\n",
       " tensor([16,  6, 14, 14, 16, 16, 16, 16, 16]),\n",
       " tensor([16,  6, 16, 16,  6, 16, 16, 16,  5, 16,  6, 14, 16, 16, 16, 16, 16,  6,\n",
       "         14, 14, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16,  4, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([ 5, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16,  4, 12, 12, 12, 16,  2, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,  6, 14, 14, 16,  5,\n",
       "         16,  5, 16]),\n",
       " tensor([16, 16, 16, 16,  7, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,  2, 16,\n",
       "         16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16,  6, 14, 14, 16, 16, 16, 16, 16, 16,\n",
       "          2, 16]),\n",
       " tensor([16, 16, 16, 16, 16]),\n",
       " tensor([ 2, 16, 16, 16, 16, 16,  2, 16, 16, 16]),\n",
       " tensor([16,  7, 15, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16,  6, 16]),\n",
       " tensor([ 6, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16,  3, 16,  3, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([ 6, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,  5, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16,  5, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,  5,\n",
       "         16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16,  2, 16]),\n",
       " tensor([16, 16,  6, 14, 16, 16, 16, 16, 16,  6, 14, 16, 16,  4, 16,  4, 16,  4,\n",
       "         16]),\n",
       " tensor([16, 16]),\n",
       " tensor([16, 16,  7, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16,  6, 14, 16, 16, 16, 16,  6, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,  2, 16, 16, 16,  2, 16, 16,\n",
       "         16, 16, 16]),\n",
       " tensor([ 3, 16,  6, 14, 16, 16, 16, 16, 16, 16, 16, 16, 16,  3, 16, 16, 16,  6,\n",
       "         14, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16,  2, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,  6, 14, 14, 16, 16, 16, 16,\n",
       "         16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,  6, 14, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16]),\n",
       " tensor([16,  6, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16, 16, 16, 16, 16,  3, 16, 16,  6, 16, 16, 16, 16,\n",
       "         16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16,  6, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16]),\n",
       " tensor([16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16,  0,  6, 14, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16,  7, 16,  7, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,  6, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([ 6, 14, 16, 16, 16, 16, 16, 16, 16,  2, 16]),\n",
       " tensor([16, 16, 16, 16, 16,  2, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16,  4, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16, 16, 16, 16,  6, 14, 16, 16, 16, 16, 16, 16,  6,\n",
       "         16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16,  6, 16, 16,  2, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16,  2, 16,  6, 16, 16, 16,  5, 13, 13, 16, 16,  6, 14,\n",
       "         14, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16,  2]),\n",
       " tensor([ 6, 16,  7, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16,  7, 15, 15, 15, 15, 15, 15, 15, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16,  2, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16,  7, 15, 15, 15, 15, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16,  2, 16, 16, 16, 16, 16, 16, 16, 16, 16,  4, 16]),\n",
       " tensor([16, 16,  2, 16,  2, 16, 16]),\n",
       " tensor([16, 16,  7, 16, 16]),\n",
       " tensor([ 6, 14, 16, 16,  0, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,  6, 16]),\n",
       " tensor([16, 16]),\n",
       " tensor([16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16,  5, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,  7, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16,  3, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,  3, 16]),\n",
       " tensor([16, 16, 16, 16, 16]),\n",
       " tensor([ 6, 16, 16, 16, 16, 16, 16, 16, 16, 16,  6, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16,  6, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16,  6, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([ 6, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16,  6, 14, 16,  6, 14, 16, 16, 16, 16, 16, 16,  0,  6, 14, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16,  2, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([ 3, 16,  6, 14, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "          2, 16,  2, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,  6, 16]),\n",
       " tensor([16, 16, 16, 16,  7, 15, 16, 16, 16, 16]),\n",
       " tensor([ 6, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16,  1, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,  6, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16,  0, 16]),\n",
       " tensor([16,  6, 14, 14, 16,  6, 14, 14, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([ 6, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16,  6, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16,  2, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16,  5, 16, 16, 16, 16, 16,  2, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16,  2, 10, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([ 5, 13, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16,  2, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16,  0, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16,  6, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16,  6, 16, 16, 16, 16, 16, 16, 16, 16, 16,  0, 16, 16, 16, 16, 16, 16,\n",
       "         16]),\n",
       " tensor([16, 16, 16,  5, 16, 16, 16, 16, 16, 16, 16, 16,  6, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16,  6, 16]),\n",
       " tensor([16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16,  4, 12, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16]),\n",
       " tensor([ 6, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16,  3, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16,  5, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,  5, 16,\n",
       "         16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16,  6, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,  6, 14,\n",
       "         16, 16,  6, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([ 5, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16]),\n",
       " tensor([ 5, 16, 16, 16, 16, 16,  2, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([ 6, 16, 16, 16, 16, 16, 16, 16,  6, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16]),\n",
       " tensor([ 6, 14, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "          4, 12, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16,  5, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([ 2, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16,  6, 14, 14, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16,  4, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,  7, 16, 16]),\n",
       " tensor([16, 16, 16,  0, 16,  2, 16,  2, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,  6, 16]),\n",
       " tensor([16, 16, 16, 16, 16,  6, 14, 16, 16, 16, 16, 16, 16, 16, 16, 16,  2, 16,\n",
       "         16, 16]),\n",
       " tensor([ 5, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,  2, 10, 10, 16]),\n",
       " tensor([16, 16, 16, 16, 16,  5, 16,  5, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([ 5, 16, 16, 16, 16, 16, 16,  4, 12, 12, 16,  2, 10, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16,  6, 16]),\n",
       " tensor([16, 16, 16, 16, 16,  6, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16,  6, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,  6, 14, 14, 16,\n",
       "          6, 14, 16,  6, 14, 16]),\n",
       " tensor([16, 16,  6, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,  2, 16, 16, 16, 16,\n",
       "         16,  2, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16]),\n",
       " tensor([16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,  6, 16,\n",
       "          6, 14, 14, 16,  5, 13, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16,  4, 12, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,  6, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16,  2, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16]),\n",
       " tensor([16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16,  5, 16,  2, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16,  2, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16,  6, 14, 16,  6, 14, 16, 16, 16]),\n",
       " tensor([ 6, 16,  6, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16]),\n",
       " tensor([16, 16, 16, 16,  7, 15, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([ 0, 16, 16, 16,  5, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16,  1,  9, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,  6, 16]),\n",
       " tensor([16, 16, 16,  6, 16, 16,  4, 12, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16,  5, 16, 16, 16, 16,  6, 14, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16,  6, 16]),\n",
       " tensor([16, 16]),\n",
       " tensor([16, 16, 16, 16,  1, 16, 16, 16,  2, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,  2,\n",
       "         16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16,  5, 16, 16, 16, 16, 16,  6, 14, 14, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16,  2, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16,  6, 14, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,  6, 16,  6, 14, 16]),\n",
       " tensor([16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,  6,\n",
       "         16, 16,  6, 14, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16,  4]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16,  2, 16]),\n",
       " tensor([16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16,  7, 15, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16,  5, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16,  6, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,  4, 16, 16, 16, 16, 16,  0,\n",
       "         16,  6, 14, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16,  2, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([ 6, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16,  6, 14, 16, 16, 16, 16, 16,  2, 16, 16, 16, 16, 16, 16, 16, 16,  6,\n",
       "         14, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,  2,\n",
       "         16, 16, 16, 16, 16,  2, 10, 10, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([ 5, 13, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16]),\n",
       " tensor([16, 16, 16,  2, 16]),\n",
       " tensor([16, 16, 16, 16, 16,  6, 16,  6, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16,  2, 10, 16,  2, 16,  2, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16]),\n",
       " tensor([16,  7, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "          6, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,  5, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,  6, 14, 16,  2, 16, 16, 16,\n",
       "         16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16]),\n",
       " tensor([16,  6, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16]),\n",
       " tensor([ 5, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16,  6, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16,  6, 14, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16,  0, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16,  2, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,  2,\n",
       "         16]),\n",
       " tensor([16, 16, 16,  5, 16]),\n",
       " tensor([16, 16, 16, 16,  5, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16]),\n",
       " tensor([16]),\n",
       " tensor([16, 16, 16,  5, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16]),\n",
       " tensor([ 6, 14, 16, 16, 16,  2, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16,  5, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([ 6, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16,  6, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16,  2, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16,  2, 10, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16,  5, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16,  6, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16,  2, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "          2, 16,  2, 16, 16, 16,  6, 14, 16,  5, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16,  2, 16,  2, 16, 16, 16, 16, 16, 16, 16, 16,  7, 15,\n",
       "         16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([ 5, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,  4, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16]),\n",
       " tensor([16,  0, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16]),\n",
       " tensor([16,  6, 14, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,  5, 16,  5,\n",
       "         16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16,  5, 16]),\n",
       " tensor([16, 16, 16, 16,  5, 16, 16,  2, 16, 16, 16, 16]),\n",
       " tensor([16, 16,  3, 16,  3, 16,  3, 16,  3, 16,  3, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16,  5, 13, 13, 16]),\n",
       " tensor([16, 16, 16]),\n",
       " tensor([16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16]),\n",
       " tensor([16, 16, 16, 16,  6, 16, 16,  2, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,  2, 16, 16, 16, 16, 16, 16,\n",
       "         16,  2, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16,  6, 14, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16,  4, 12, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16,  6, 14, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16]),\n",
       " tensor([ 4, 16,  4, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16, 16,  6, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16,  7, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16,  7, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16,  7, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16]),\n",
       " tensor([16, 16,  3, 16, 16, 16, 16, 16, 16,  3, 16]),\n",
       " tensor([16,  6, 14, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16,  6, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([ 6, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16,  6, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16,  4, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16]),\n",
       " tensor([16, 16, 16, 16,  5, 16,  5, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16,  4, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16,  4, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16,  6, 16, 16,  6, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16,  6, 14, 16, 16, 16, 16,  6, 14, 16]),\n",
       " tensor([16, 16, 16, 16,  2, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,  2, 16, 16,\n",
       "         16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16,  5, 16, 16, 16, 16, 16, 16,  6, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16,  6, 14, 16, 16, 16, 16, 16, 16, 16,  6, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([ 6, 14, 16, 16, 16]),\n",
       " tensor([ 6, 16, 16, 16,  4]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16,  0, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16,  5, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16,  4, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16,  4, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16,  0,  6, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16,  6, 14, 16, 16, 16, 16, 16, 16,  0, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16,  2, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16,  3, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16,  5, 16,  6, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16]),\n",
       " tensor([ 6, 14, 14, 16, 16, 16,  6, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,  6, 16, 16,\n",
       "         16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16,  2, 16]),\n",
       " tensor([ 6, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,  2, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16,  2, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16]),\n",
       " tensor([ 6, 16, 16, 16, 16, 16, 16, 16,  2, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([ 5, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,  2, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16,  6, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16]),\n",
       " tensor([ 6, 16, 16, 16, 16, 16, 16, 16, 16, 16,  2, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16,  5, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16,  2, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16,  6, 14, 16,  5, 13, 16, 16, 16, 16, 16, 16, 16, 16,  4, 16,  2, 16,\n",
       "          2, 16]),\n",
       " tensor([16, 16, 16,  4, 16, 16, 16, 16,  4, 16,  4, 16,  4, 16,  4, 16]),\n",
       " tensor([ 6, 16, 16, 16, 16, 16,  2, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16,  5, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,  6,\n",
       "         14, 16,  6, 14, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,  2, 16,\n",
       "          7, 16,  6, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([ 7, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16,  6, 14, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([ 5, 13, 13, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16]),\n",
       " tensor([16,  5, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16,  2, 10, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([ 6, 14, 16, 16, 16, 16,  0, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16,  6, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,  5, 16, 16, 16,\n",
       "         16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16,  5, 16, 16, 16]),\n",
       " tensor([16,  7, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16]),\n",
       " tensor([ 5, 16, 16, 16,  6, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,  2, 16,\n",
       "          2, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16, 16,  6, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,  6, 14, 16,  5,\n",
       "         13, 16,  5, 16, 16,  5, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16,  6, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16]),\n",
       " tensor([16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([ 5, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "         16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16, 16, 16]),\n",
       " tensor([16, 16, 16, 16]),\n",
       " tensor([16, 16, 16,  6, 16, 16, 16, 16, 16,  0,  6, 14, 16, 16, 16, 16, 16,  0,\n",
       "         16, 16, 16]),\n",
       " ...]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1693abf4",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "only integer tensors of a single element can be converted to an index",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [29], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m offsets \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mLongTensor(offsets)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m#word_lengths = torch.LongTensor(word_lengths)\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLongTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: only integer tensors of a single element can be converted to an index"
     ]
    }
   ],
   "source": [
    "input_ids\n",
    "attention_mask\n",
    "offsets = torch.LongTensor(offsets)\n",
    "word_lengths = torch.LongTensor(word_lengths)\n",
    "y = torch.LongTensor(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47306f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad(l, content, width):\n",
    "    l.extend([content] * (width - len(l)))\n",
    "    return l\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "40398bb9",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [26], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTensorDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43moffsets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mword_lengths\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/utils/data/dataset.py:189\u001b[0m, in \u001b[0;36mTensorDataset.__init__\u001b[0;34m(self, *tensors)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39mtensors: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 189\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;43mall\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSize mismatch between tensors\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    190\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtensors \u001b[38;5;241m=\u001b[39m tensors\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/utils/data/dataset.py:189\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39mtensors: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 189\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mall\u001b[39m(tensors[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[43mtensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m(\u001b[38;5;241m0\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m tensor \u001b[38;5;129;01min\u001b[39;00m tensors), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSize mismatch between tensors\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    190\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtensors \u001b[38;5;241m=\u001b[39m tensors\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'size'"
     ]
    }
   ],
   "source": [
    "train_dataset = data.TensorDataset(input_ids,\n",
    "                                   attention_mask,\n",
    "                                   offsets,\n",
    "                                   word_lengths,\n",
    "                                   y)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7d894680",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Tensor, torch.Tensor, list, list, list)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(input_ids), type(attention_mask), type(offsets), type(word_lengths), type(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "3cbb4280",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12668, 12668, 12668, 12668, 12668)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(input_ids), len(attention_mask), len(offsets), len(word_lengths), len(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c237749f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64 64 64 17 17\n",
      "64 64 64 22 22\n",
      "64 64 64 32 32\n",
      "64 64 64 21 21\n",
      "64 64 64 30 30\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(len(input_ids[i]), len(attention_mask[i]), len(offsets[i]), len(word_lengths[i]), len(y[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c37212",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenizer(train_texts,\n",
    "          return_tensors=\"pt\",\n",
    "          padding=True,\n",
    "          truncation=True,\n",
    "          max_length=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "id": "32ed937a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  1697, 14319,  ...,     0,     0,     0],\n",
       "        [  101, 12786, 24181,  ...,     0,     0,     0],\n",
       "        [  101,   146,  4121,  ...,  1766,  7174,   102],\n",
       "        ...,\n",
       "        [  101, 14177,  1116,  ...,     0,     0,     0],\n",
       "        [  101,   156, 17945,  ...,     0,     0,     0],\n",
       "        [  101, 19569, 24577,  ...,   171, 19921,   102]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 1, 1, 1],\n",
       "        ...,\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 1, 1, 1]])}"
      ]
     },
     "execution_count": 518,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "id": "79d1d16c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "President Barack Obama sa i sin Kairo-tale at islam alltid har vært en del av USA .\n",
      "['[CLS]', 'President', 'Barack', 'Obama', 'sa', 'i', 'sin', 'Kai', '##ro', '-', 'tale', 'at', 'is', '##lam', 'all', '##ti', '##d', 'ha', '##r', 'v', '##æ', '##rt', 'en', 'del', 'a', '##v', 'USA', '.', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "sent = train_texts[0]\n",
    "ids = tokenizer(sent).input_ids\n",
    "print(sent)\n",
    "print([tokenizer.convert_ids_to_tokens(i) for i in ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "id": "62dd949b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29,\n",
       " [(0, 0),\n",
       "  (0, 9),\n",
       "  (10, 16),\n",
       "  (17, 22),\n",
       "  (23, 25),\n",
       "  (26, 27),\n",
       "  (28, 31),\n",
       "  (32, 35),\n",
       "  (35, 37),\n",
       "  (37, 38),\n",
       "  (38, 42),\n",
       "  (43, 45),\n",
       "  (46, 48),\n",
       "  (48, 51),\n",
       "  (52, 55),\n",
       "  (55, 57),\n",
       "  (57, 58),\n",
       "  (59, 61),\n",
       "  (61, 62),\n",
       "  (63, 64),\n",
       "  (64, 65),\n",
       "  (65, 67),\n",
       "  (68, 70),\n",
       "  (71, 74),\n",
       "  (75, 76),\n",
       "  (76, 77),\n",
       "  (78, 81),\n",
       "  (82, 83),\n",
       "  (0, 0)])"
      ]
     },
     "execution_count": 512,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "offsets = tokenizer(sent, return_offsets_mapping=True).offset_mapping\n",
    "len(offsets), offsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "id": "38251d25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17, [9, 6, 5, 2, 1, 3, 10, 2, 5, 6, 3, 4, 2, 3, 2, 3, 1])"
      ]
     },
     "execution_count": 516,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_lengths = [len(word) for word in sent.split()]\n",
    "len(word_lengths), word_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "id": "fafa7718",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'President Barack Obama sa i sin Kairo-tale at islam alltid har vært en del av USA .'"
      ]
     },
     "execution_count": 504,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_texts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "id": "96731e19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  101,  1697, 14319,  7661, 21718,   178, 11850, 13354,  2180,   118,\n",
       "         8144,  1120,  1110,  7609,  1155,  3121,  1181,  5871,  1197,   191,\n",
       "        28200,  3740,  4035,  3687,   170,  1964,  3066,   119,   102,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0])"
      ]
     },
     "execution_count": 503,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens[\"input_ids\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce06d131",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
